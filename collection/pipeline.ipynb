{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Data Collection Pipeline using Netunicorn**\n",
    "\n",
    "This document outlines a data collection pipeline designed around Netunicorn, a specialized library for gathering reliable networking data.\n",
    "\n",
    "### **Pipeline Objective**\n",
    "\n",
    "The primary goal of this pipeline is to capture detailed packet trace data while simulating real-world user interactions with YouTube videos. This involves using Selenium, a web testing automation library, to randomly pause and unpause videos. A custom task specifically developed for this purpose mimics user actions and collects critical data points during these interactions.\n",
    "\n",
    "### **Data Collected**\n",
    "\n",
    "The pipeline collects the following data:\n",
    "\n",
    "* **`Packet Trace:`** Detailed network packet information captured during different video playback states.\n",
    "* **`Video State:`** Real-time status of the YouTube video, categorized as playing, paused, or buffering.\n",
    "* **`Latency:`** Measurements of network response delay, providing insights into network efficiency.\n",
    "* **`YouTube Stats for Nerds:`** A set of advanced metrics provided by YouTube, offering deeper insights into video and network performance.\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import json\n",
    "import random\n",
    "import subprocess\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from netunicorn.base import Task, Success, Failure\n",
    "from netunicorn.base import DockerImage, Experiment, ExperimentStatus, Pipeline\n",
    "from netunicorn.client.remote import RemoteClient, RemoteClientException\n",
    "from netunicorn.library.tasks.capture.tcpdump import StartCapture, StopNamedCapture\n",
    "from netunicorn.library.tasks.upload.fileio import UploadToFileIO\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.common.exceptions import StaleElementReferenceException\n",
    "from selenium.webdriver import ActionChains"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Data Combiner**\n",
    "\n",
    "A Task designed to take the pcap file and json file generated by the Pausing Simulator task and the StartCapture task and combine it into a csv file, this was made to save a bit of time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataCombiner(Task):\n",
    "    def __init__(self, pcap_filepath : str, video_details_filepath : str,  res_filepath : str) -> None:\n",
    "        super().__init__()\n",
    "        self.pcap_filepath = pcap_filepath\n",
    "        self.video_details_filepath = video_details_filepath\n",
    "        self.res_filepath = res_filepath\n",
    "\n",
    "    def run(self):\n",
    "        try:\n",
    "            self.create_csv()\n",
    "            json_df = self.pull_json()\n",
    "            \n",
    "            # DROPPING UNWANTED COLUMNS\n",
    "            json_df = json_df.drop(columns=['latency', 'yt_metrics'])\n",
    "            \n",
    "            csv_df = self.pull_csv()\n",
    "            merged_df = self.combine(csv_df, json_df)\n",
    "            self.save_csv(merged_df)\n",
    "            return Success(\"Successfully Combined Data\")\n",
    "        except Exception as e:\n",
    "            return Failure(str(e))\n",
    "        \n",
    "        \n",
    "    def create_csv(self):\n",
    "        with open(self.res_filepath, 'w') as f:\n",
    "            process = subprocess.run([\n",
    "                \"tshark\", \"-r\", self.pcap_filepath,\n",
    "                \"-T\", \"fields\",\n",
    "                \"-e\", \"frame.number\",\n",
    "                \"-e\", \"frame.time_epoch\",\n",
    "                \"-e\", \"ip.src\",\n",
    "                \"-e\", \"ip.dst\",\n",
    "                \"-e\", \"_ws.col.Protocol\",\n",
    "                \"-e\", \"frame.len\",\n",
    "                \"-e\", \"_ws.col.Info\",\n",
    "                \"-E\", \"header=y\",\n",
    "                \"-E\", \"separator=;\"\n",
    "            ], stdout=f, stderr=subprocess.PIPE, text=True)\n",
    "\n",
    "            if process.returncode != 0:\n",
    "                raise Exception(f\"tshark error: {process.stderr}\")\n",
    "            elif process.stderr:\n",
    "                print(f\"tshark warnings: {process.stderr}\")\n",
    "\n",
    "    def pull_json(self):\n",
    "        with open(self.video_details_filepath, 'r') as file:\n",
    "            data = json.load(file)\n",
    "        return pd.DataFrame(data)\n",
    "    \n",
    "    def save_csv(self, df):\n",
    "        df.to_csv(self.res_filepath)\n",
    "    \n",
    "    def pull_csv(self):\n",
    "        return pd.read_csv(self.res_filepath, sep=';')\n",
    "    \n",
    "    def combine(self, csv_df, json_df):\n",
    "        csv_df.rename(columns={\n",
    "            'frame.time_epoch': 'Time',\n",
    "            'frame.number': 'No',\n",
    "            'ip.src': 'Source',\n",
    "            'ip.dst': 'Destination',\n",
    "            '_ws.col.Protocol': 'Protocol',\n",
    "            'frame.len': 'Length',\n",
    "            '_ws.col.Info': 'Info',\n",
    "        }, inplace=True)\n",
    "        \n",
    "        # Convert times to float\n",
    "        csv_df['Time'] = csv_df['Time'].astype('float64')\n",
    "        json_df['time'] = json_df['time'].astype('float64')\n",
    "\n",
    "        # Sort dataframes by time\n",
    "        csv_df = csv_df.sort_values('Time')\n",
    "        json_df = json_df.sort_values('time')\n",
    "\n",
    "        # Find the time range in json_df\n",
    "        min_time = json_df['time'].min()\n",
    "        max_time = json_df['time'].max()\n",
    "\n",
    "        # Filter csv_df to be within the time range of json_df\n",
    "        csv_df = csv_df[(csv_df['Time'] >= min_time) & (csv_df['Time'] <= max_time)]\n",
    "\n",
    "        merged_df = pd.merge_asof(csv_df, json_df, left_on='Time', right_on='time', direction='nearest')\n",
    "        return merged_df\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **PausingSimulator**\n",
    "\n",
    "This task is designed to simulate user behavior, it pauses and unpauses a video repeatedly at random intervals using selenium webdriver and it also collects youtube stats for nerds data, as well as latency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PausingSimulator(Task):\n",
    "    def __init__(self, video_url=None, duration=None, filepath=None, chrome_location=None, webdriver_arguments=None) -> None:\n",
    "        super().__init__()\n",
    "        self.video_url = video_url\n",
    "        self.duration = duration\n",
    "        self.filepath = filepath\n",
    "        self.chrome_location = chrome_location or '/usr/bin/chromium'\n",
    "        self.webdriver_arguments = webdriver_arguments or []\n",
    "        self.drive = None\n",
    "        self.log = []\n",
    "        self.sfn_open = False\n",
    "    \n",
    "    def run(self):\n",
    "        try:\n",
    "            self.init_webdriver()\n",
    "            self.driver.get(self.video_url)\n",
    "            start_time = self.wait_until_start()\n",
    "            \n",
    "            while time.time() - start_time < self.duration:\n",
    "                temp = random.randint(0, 20)  \n",
    "                if temp % 3 == 0:  \n",
    "                    delay = random.randint(5, 30)  \n",
    "                elif temp % 3 == 1:\n",
    "                    delay = random.randint(30, 60) \n",
    "                else:\n",
    "                    delay = int(random.gauss(20, 5)) \n",
    "\n",
    "                                \n",
    "                for _ in range(delay):\n",
    "                    self.log_data()\n",
    "                    time.sleep(1)\n",
    "                self.toggle_video_state()\n",
    "                pass\n",
    "            \n",
    "            self.save_file()\n",
    "            self.driver.quit()\n",
    "            return Success(\"Successfully Watched Video and Simulated Pausing Events\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred: {e}\")\n",
    "            return Failure(str(e))\n",
    "    \n",
    "    def get_network_metrics(self):\n",
    "        try:\n",
    "            response = subprocess.run([\"ping\", \"-c\", \"1\", 'www.youtube.com'], capture_output=True)\n",
    "            output = response.stdout.decode()\n",
    "            latency = output.split(\"time=\")[-1].split(\" ms\")[0]\n",
    "\n",
    "            return latency\n",
    "        except Exception as e:\n",
    "            return f\"Error measuring latency: {e}\"\n",
    "\n",
    "    \n",
    "    def get_youtube_metrics(self):\n",
    "        \"\"\"Fetches metrics from 'Stats for nerds'.\"\"\"\n",
    "        \n",
    "        DIVS = [1, 2, 3, 4, 5, 7, 9, 10, 11]\n",
    "\n",
    "        DIV_TO_KEY = {\n",
    "            1: 'Video ID',\n",
    "            2: 'Viewport / Frame Size',\n",
    "            3: 'Current Res / Optimal Res',\n",
    "            4: 'Volume / Normalized',\n",
    "            5: 'Codecs',\n",
    "            7: 'Color',  \n",
    "            9: 'Connection Speed',  \n",
    "            10: 'Network Activity',  \n",
    "            11: 'Buffer Health',  \n",
    "        }\n",
    "\n",
    "        try:\n",
    "            if not self.enable_stats_for_nerds():\n",
    "                return \"Unable to open Stats for nerds\"\n",
    "\n",
    "            stat_dict = {}\n",
    "            for div_id in DIVS:\n",
    "                try:\n",
    "                    elem = self.driver.find_element(By.CSS_SELECTOR, f\".html5-video-info-panel-content > div:nth-child({div_id}) > span:nth-child(2)\")\n",
    "                    stat_dict[DIV_TO_KEY[div_id]] = elem.text\n",
    "                except Exception as e:\n",
    "                    print(f\"An error occurred in get_stats for DIV {div_id}: {e}\")\n",
    "                    stat_dict[DIV_TO_KEY.get(div_id, f\"Unknown_DIV_{div_id}\")] = 'Error'\n",
    "            return stat_dict\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred in get_youtube_metrics: {e}\")\n",
    "            return Failure(str(e))\n",
    "    \n",
    "    def get_video_state(self):\n",
    "        try:\n",
    "            player_status = self.driver.execute_script(\"return document.getElementById('movie_player').getPlayerState()\")\n",
    "            return player_status\n",
    "            pass\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred: {e}\")\n",
    "            return Failure(str(e))\n",
    "    \n",
    "    def toggle_video_state(self):\n",
    "        try:\n",
    "            WebDriverWait(self.driver, 10).until(EC.presence_of_element_located((By.CLASS_NAME, \"ytp-play-button\")))\n",
    "\n",
    "            play_button = self.driver.find_element(By.CLASS_NAME, \"ytp-play-button\")\n",
    "\n",
    "            self.driver.execute_script(\"arguments[0].click();\", play_button)\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred: {e}\")\n",
    "            return Failure(str(e))\n",
    "\n",
    "    def init_webdriver(self):\n",
    "        try:\n",
    "            options = Options()\n",
    "            for argument in self.webdriver_arguments:\n",
    "                options.add_argument(argument)\n",
    "            self.driver = webdriver.Chrome(options=options)\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred: {e}\")\n",
    "            return Failure(str(e))\n",
    "    \n",
    "    def save_file(self):\n",
    "        try:\n",
    "            with open(self.filepath, \"w\") as json_file:\n",
    "                json.dump(self.log, json_file)\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred: {e}\")\n",
    "            return Failure(str(e))\n",
    "\n",
    "        \n",
    "    def wait_until_start(self):\n",
    "        try:\n",
    "            video_is_playing = False\n",
    "            curr_time = self.find_element(By.CLASS_NAME, \"ytp-time-current\")\n",
    "            while not video_is_playing:\n",
    "                time.sleep(1)\n",
    "                try:\n",
    "                    curr_time = self.find_element(By.CLASS_NAME, \"ytp-time-current\")\n",
    "                    video_is_playing = curr_time.text[:4] == curr_time.text[-4:]\n",
    "                except StaleElementReferenceException:\n",
    "                    pass\n",
    "            return time.time()\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred: {e}\")\n",
    "            return Failure(str(e))\n",
    "\n",
    "    def find_element(self, by, value):\n",
    "        try:\n",
    "            return WebDriverWait(self.driver, 10).until(EC.presence_of_element_located((by, value)))\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred: {e}\")\n",
    "            return Failure(str(e))\n",
    "    \n",
    "    def enable_stats_for_nerds(self):\n",
    "        \"\"\"Enables the 'Stats for nerds' feature on the YouTube player.\"\"\"\n",
    "        try:\n",
    "            \n",
    "            if self.sfn_open:\n",
    "                return True\n",
    "            \n",
    "            movie_player = self.driver.find_element(By.ID, 'movie_player')\n",
    "            ActionChains(self.driver).move_to_element(movie_player).context_click().perform()\n",
    "            options = self.driver.find_elements(By.CLASS_NAME, 'ytp-menuitem')\n",
    "            for option in options:\n",
    "                option_child = option.find_element(By.CLASS_NAME, 'ytp-menuitem-label')\n",
    "                if option_child.text == 'Stats for nerds':\n",
    "                    option_child.click()\n",
    "                    self.sfn_open = True\n",
    "                    return True\n",
    "            return False\n",
    "        except Exception as e:\n",
    "            print(f\"Error enabling 'Stats for nerds': {e}\")\n",
    "            return False\n",
    "    \n",
    "    def log_data(self):\n",
    "        curr_state = self.get_video_state()\n",
    "        yt_metrics = self.get_youtube_metrics()\n",
    "        latency = self.get_network_metrics()\n",
    "\n",
    "        self.log.append({\n",
    "                    \"time\": time.time(),\n",
    "                    \"curr_state\": curr_state,\n",
    "                    \"yt_metrics\": yt_metrics,\n",
    "                    \"latency\": latency\n",
    "                })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ENDPOINT = 'https://pinot.cs.ucsb.edu/netunicorn'\n",
    "LOGIN = 'team_lb'\n",
    "PASSWORD = 'userbehavior023'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = RemoteClient(endpoint=ENDPOINT, login=LOGIN, password=PASSWORD)\n",
    "nodes = client.get_nodes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[aws-fargate-A-team_lb-1,\n",
       " aws-fargate-B-team_lb-2,\n",
       " aws-fargate-A-team_lb-3,\n",
       " aws-fargate-B-team_lb-4,\n",
       " aws-fargate-A-team_lb-5,\n",
       " aws-fargate-B-team_lb-6]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "working_nodes = nodes.filter(lambda node: \"aws\" in node.name and \"ARM64\" not in node.name).take(6)\n",
    "working_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "capture_task_name = \"capture_task\"\n",
    "capture_file_path = \"/tmp/capture_task.pcap\"\n",
    "tcpdump_filter = (\n",
    "    \"tcp or udp \"\n",
    "    \"and not icmp and not arp \"\n",
    "    \"and not port 22 \"\n",
    "    \"and not host 169.254.169.254\"\n",
    ")\n",
    "args=[\n",
    "        \"-i\", \"any\",\n",
    "        \"-tttt\",  \n",
    "        \"-s\", \"0\",\n",
    "        \"-w\", capture_file_path,\n",
    "        tcpdump_filter.strip()\n",
    "    ]\n",
    "\n",
    "start_capture = StartCapture(filepath=capture_file_path, arguments=args, name=capture_task_name)\n",
    "stop_capture = StopNamedCapture(start_capture_task_name=capture_task_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_url='https://www.youtube.com/watch?v=KcMlPl9jArM'\n",
    "duration=600\n",
    "video_details_filepath='/tmp/video_details.json'\n",
    "webdriver_args = [\n",
    "    '--headless', \n",
    "    '--no-sandbox', \n",
    "    '--autoplay-policy=no-user-gesture-required', \n",
    "    '--disable-dev-shm-usage'\n",
    "    ]\n",
    "\n",
    "simulate_video = PausingSimulator(video_url=video_url,duration=duration, filepath=video_details_filepath, webdriver_arguments=webdriver_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_filepath =f'/tmp/dataset_{duration}_sec.csv'\n",
    "combine_data = DataCombiner(pcap_filepath=capture_file_path, video_details_filepath=video_details_filepath, res_filepath=result_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = (\n",
    "    Pipeline()\n",
    "    .then(start_capture)\n",
    "    .then(simulate_video)\n",
    "    .then(stop_capture)\n",
    "    .then(combine_data)\n",
    "    .then(UploadToFileIO(filepath=result_filepath, expires=\"1d\"))\n",
    ")\n",
    "\n",
    "experiment = Experiment().map(pipeline, working_nodes)\n",
    "docker_image = DockerImage(image='bravola/netunicorn:v3')\n",
    "for deployment in experiment:\n",
    "     deployment.environment_definition = docker_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_label = \"lb_ds_1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ExperimentStatus.PREPARING\n",
      "ExperimentStatus.READY\n",
      "ExperimentStatus.RUNNING\n",
      "ExperimentStatus.RUNNING\n",
      "ExperimentStatus.RUNNING\n",
      "ExperimentStatus.RUNNING\n",
      "ExperimentStatus.FINISHED\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ExperimentExecutionInformation:\n",
       "status: ExperimentStatus.FINISHED\n",
       "experiment: \n",
       " - Deployment: Node=aws-fargate-A-team_lb-1, executor_id=180c27bd-0d34-4004-af10-3b5ee1b0671f, prepared=True, error=None\n",
       " - Deployment: Node=aws-fargate-B-team_lb-2, executor_id=adb87173-f9e0-4102-977c-5bddb9441f68, prepared=True, error=None\n",
       " - Deployment: Node=aws-fargate-A-team_lb-3, executor_id=a39fd931-bdaa-4f62-ac86-e821c0cec6c3, prepared=True, error=None\n",
       " - Deployment: Node=aws-fargate-B-team_lb-4, executor_id=1823ad71-3f62-47eb-be44-d8ea2305fd0d, prepared=True, error=None\n",
       " - Deployment: Node=aws-fargate-A-team_lb-5, executor_id=44dcd810-6a16-4788-acae-43333720f402, prepared=True, error=None\n",
       " - Deployment: Node=aws-fargate-B-team_lb-6, executor_id=7b646ce2-bff2-4e7a-af1f-7af86a8039f8, prepared=True, error=None\n",
       "execution_result:\n",
       "[DeploymentExecutionResult:\n",
       "  Node: aws-fargate-A-team_lb-1\n",
       "  Result: <class 'NoneType'>\n",
       "   None\n",
       "  Logs:\n",
       "    Parsed configuration: Gateway located on https://pinot.cs.ucsb.edu/netunicorn/gateway\n",
       "    Current directory: /app\n",
       "    code expected at most 16 arguments, got 18\n",
       "    Traceback (most recent call last):\n",
       "      File \"/usr/local/lib/python3.10/site-packages/netunicorn/executor/executor.py\", line 94, in __call__\n",
       "        self.request_pipeline()\n",
       "      File \"/usr/local/lib/python3.10/site-packages/netunicorn/executor/executor.py\", line 143, in request_pipeline\n",
       "        self.pipeline = cloudpickle.loads(pipeline)\n",
       "    TypeError: code expected at most 16 arguments, got 18\n",
       "    Failed to execute pipeline. Shutting down.\n",
       "\n",
       ", DeploymentExecutionResult:\n",
       "  Node: aws-fargate-B-team_lb-2\n",
       "  Result: <class 'NoneType'>\n",
       "   None\n",
       "  Logs:\n",
       "    Parsed configuration: Gateway located on https://pinot.cs.ucsb.edu/netunicorn/gateway\n",
       "    Current directory: /app\n",
       "    code expected at most 16 arguments, got 18\n",
       "    Traceback (most recent call last):\n",
       "      File \"/usr/local/lib/python3.10/site-packages/netunicorn/executor/executor.py\", line 94, in __call__\n",
       "        self.request_pipeline()\n",
       "      File \"/usr/local/lib/python3.10/site-packages/netunicorn/executor/executor.py\", line 143, in request_pipeline\n",
       "        self.pipeline = cloudpickle.loads(pipeline)\n",
       "    TypeError: code expected at most 16 arguments, got 18\n",
       "    Failed to execute pipeline. Shutting down.\n",
       "\n",
       ", DeploymentExecutionResult:\n",
       "  Node: aws-fargate-A-team_lb-3\n",
       "  Result: <class 'NoneType'>\n",
       "   None\n",
       "  Logs:\n",
       "    Parsed configuration: Gateway located on https://pinot.cs.ucsb.edu/netunicorn/gateway\n",
       "    Current directory: /app\n",
       "    code expected at most 16 arguments, got 18\n",
       "    Traceback (most recent call last):\n",
       "      File \"/usr/local/lib/python3.10/site-packages/netunicorn/executor/executor.py\", line 94, in __call__\n",
       "        self.request_pipeline()\n",
       "      File \"/usr/local/lib/python3.10/site-packages/netunicorn/executor/executor.py\", line 143, in request_pipeline\n",
       "        self.pipeline = cloudpickle.loads(pipeline)\n",
       "    TypeError: code expected at most 16 arguments, got 18\n",
       "    Failed to execute pipeline. Shutting down.\n",
       "\n",
       ", DeploymentExecutionResult:\n",
       "  Node: aws-fargate-B-team_lb-4\n",
       "  Result: <class 'NoneType'>\n",
       "   None\n",
       "  Logs:\n",
       "    Parsed configuration: Gateway located on https://pinot.cs.ucsb.edu/netunicorn/gateway\n",
       "    Current directory: /app\n",
       "    code expected at most 16 arguments, got 18\n",
       "    Traceback (most recent call last):\n",
       "      File \"/usr/local/lib/python3.10/site-packages/netunicorn/executor/executor.py\", line 94, in __call__\n",
       "        self.request_pipeline()\n",
       "      File \"/usr/local/lib/python3.10/site-packages/netunicorn/executor/executor.py\", line 143, in request_pipeline\n",
       "        self.pipeline = cloudpickle.loads(pipeline)\n",
       "    TypeError: code expected at most 16 arguments, got 18\n",
       "    Failed to execute pipeline. Shutting down.\n",
       "\n",
       ", DeploymentExecutionResult:\n",
       "  Node: aws-fargate-A-team_lb-5\n",
       "  Result: <class 'NoneType'>\n",
       "   None\n",
       "  Logs:\n",
       "    Parsed configuration: Gateway located on https://pinot.cs.ucsb.edu/netunicorn/gateway\n",
       "    Current directory: /app\n",
       "    code expected at most 16 arguments, got 18\n",
       "    Traceback (most recent call last):\n",
       "      File \"/usr/local/lib/python3.10/site-packages/netunicorn/executor/executor.py\", line 94, in __call__\n",
       "        self.request_pipeline()\n",
       "      File \"/usr/local/lib/python3.10/site-packages/netunicorn/executor/executor.py\", line 143, in request_pipeline\n",
       "        self.pipeline = cloudpickle.loads(pipeline)\n",
       "    TypeError: code expected at most 16 arguments, got 18\n",
       "    Failed to execute pipeline. Shutting down.\n",
       "\n",
       ", DeploymentExecutionResult:\n",
       "  Node: aws-fargate-B-team_lb-6\n",
       "  Result: <class 'NoneType'>\n",
       "   None\n",
       "  Logs:\n",
       "    Parsed configuration: Gateway located on https://pinot.cs.ucsb.edu/netunicorn/gateway\n",
       "    Current directory: /app\n",
       "    code expected at most 16 arguments, got 18\n",
       "    Traceback (most recent call last):\n",
       "      File \"/usr/local/lib/python3.10/site-packages/netunicorn/executor/executor.py\", line 94, in __call__\n",
       "        self.request_pipeline()\n",
       "      File \"/usr/local/lib/python3.10/site-packages/netunicorn/executor/executor.py\", line 143, in request_pipeline\n",
       "        self.pipeline = cloudpickle.loads(pipeline)\n",
       "    TypeError: code expected at most 16 arguments, got 18\n",
       "    Failed to execute pipeline. Shutting down.\n",
       "\n",
       "]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "try:\n",
    "    client.delete_experiment(experiment_label)\n",
    "except RemoteClientException:\n",
    "    pass\n",
    "\n",
    "client.prepare_experiment(experiment, experiment_label)\n",
    "\n",
    "while True:\n",
    "    info = client.get_experiment_status(experiment_label)\n",
    "    print(info.status)\n",
    "    if info.status == ExperimentStatus.READY:\n",
    "        break\n",
    "    time.sleep(20)\n",
    "\n",
    "client.start_execution(experiment_label)\n",
    "\n",
    "while True:\n",
    "    info = client.get_experiment_status(experiment_label)\n",
    "    print(info.status)\n",
    "    if info.status != ExperimentStatus.RUNNING:\n",
    "        break\n",
    "    time.sleep(20)\n",
    "\n",
    "client.get_experiments()[experiment_label]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
